---
key: 2020-Kim-sigcomm
date: 2020-08-01
title: "TEA: Enabling State-Intensive Network Functions on Programmable Switches"
venue: "ACM SIGCOMM Conference"
authors: Daehyeok Kim, Zaoxing Liu, Yibo Zhu, Changhoon Kim, Jeongkeun Lee, Vyas Sekar and Srinivasan Seshan
webpage: https://doi.org/10.1145/3387514.3405855
localpdf: papers/2020-Kim-sigcomm/2020-Kim-sigcomm.pdf
---

<pre>
@inproceedings{2020-Kim-sigcomm,
    author = "Kim, Daehyeok and Liu, Zaoxing and Zhu, Yibo and Kim, Changhoon and Lee, Jeongkeun and Sekar, Vyas and Seshan, Srinivasan",
    title = "TEA: Enabling State-Intensive Network Functions on Programmable Switches",
    year = "2020",
    month = "August",
    isbn = "9781450379557",
    publisher = "Association for Computing Machinery",
    address = "New York, NY, USA",
    url = "https://doi.org/10.1145/3387514.3405855",
    doi = "10.1145/3387514.3405855",
    abstract = "Programmable switches have been touted as an attractive alternative for deploying network functions (NFs) such as network address translators (NATs), load balancers, and firewalls. However, their limited memory capacity has been a major stumbling block that has stymied their adoption for supporting state-intensive NFs such as cloud-scale NATs and load balancers that maintain millions of flow-table entries. In this paper, we explore a new approach that leverages DRAM on servers available in typical NFV clusters. Our new system architecture, called TEA (Table Extension Architecture), provides a virtual table abstraction that allows NFs on programmable switches to look up large virtual tables built on external DRAM. Our approach enables switch ASICs to access external DRAM purely in the data plane without involving CPUs on servers. We address key design and implementation challenges in realizing this idea. We demonstrate its feasibility and practicality with our implementation on a Tofino-based programmable switch. Our evaluation shows that NFs built with TEA can look up table entries on external DRAM with low and predictable latency (1.8-2.2 μs) and the lookup throughput can be linearly scaled with additional servers (138 million lookups per seconds with 8 servers).",
    booktitle = "ACM SIGCOMM Conference",
    pages = "90–106",
    numpages = "17",
    keywords = "Data centers, Programmable switches, Remote Direct Memory Access, Network Function Virtualization, Programmable networks",
    location = "Virtual Event, USA",
    series = "SIGCOMM '20"
}

</pre>
